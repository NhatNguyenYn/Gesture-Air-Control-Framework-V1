# ğŸ–ï¸ Gesture Air-Control Framework

> ğŸ‡»ğŸ‡³ Äiá»u khiá»ƒn mÃ¡y tÃ­nh khÃ´ng cháº¡m báº±ng cá»­ chá»‰ tay qua webcam
> ğŸ‡¬ğŸ‡§ Touchless gesture-based PC control using real-time hand tracking

---

## ğŸ¯ Overview | Tá»•ng quan

**Gesture Air-Control Framework** lÃ  má»™t framework thá»‹ giÃ¡c mÃ¡y tÃ­nh thá»i gian thá»±c cho phÃ©p ngÆ°á»i dÃ¹ng tÆ°Æ¡ng tÃ¡c vá»›i mÃ¡y tÃ­nh chá»‰ báº±ng cá»­ chá»‰ tay, sá»­ dá»¥ng webcam. Dá»± Ã¡n táº­p trung vÃ o sá»± linh hoáº¡t, hiá»‡u suáº¥t vÃ  kháº£ nÄƒng má»Ÿ rá»™ng, phá»¥c vá»¥ má»¥c Ä‘Ã­ch há»c táº­p, trÃ¬nh diá»…n cÃ´ng nghá»‡ vÃ  nghiÃªn cá»©u giao diá»‡n ngÆ°á»i â€“ mÃ¡y (HCI).

This is a real-time computer vision framework that enables gesture-based PC interaction through webcam input. It is designed to be modular, performant, and extensible â€” perfect for learning, showcasing, and HCI experimentation.

---

## âœ… Features | TÃ­nh nÄƒng chÃ­nh

| Feature                | Description                                                               |
| ---------------------- | ------------------------------------------------------------------------- |
| âœï¸ Virtual Air-Painter | Draw in the air using your index finger like a pen                        |
| ğŸ–±ï¸ Virtual Air-Mouse  | Move cursor, click, drag using natural hand gestures                      |
| ğŸ”Š Volume Air-Control  | Adjust system volume by measuring finger distance                         |
| ğŸ” Gesture Inspector   | Display live hand recognition (left/right hand, fingers up, landmarks...) |

---

## âš™ï¸ Technologies Used | CÃ´ng nghá»‡ sá»­ dá»¥ng

| Technology | Purpose                                |
| ---------- | -------------------------------------- |
| Python 3.x | Main programming language              |
| OpenCV     | Video capture and image processing     |
| MediaPipe  | 21-point hand tracking                 |
| PyAutoGUI  | Mouse and keyboard control             |
| PyCAW      | Audio volume adjustment (Windows only) |
| Tkinter    | GUI display (for menu/config)          |

---

## ğŸ§  Architecture Highlights | Kiáº¿n trÃºc ná»•i báº­t

* ğŸ§© **Modular Design** â€“ Each function (hand tracking, mouse, volume...) is isolated in its own controller class â†’ easier to scale.
* ğŸ”„ **Multithreading** â€“ Camera processing, GUI, and logic run on separate threads for low-latency performance.
* ğŸ“ **Vector-based Gesture Recognition** â€“ More precise and angle-independent than hard-coded heuristics.
* âœ¨ **Visual Feedback** â€“ Live overlay, cursor color changes, gesture highlights, UI cues.

---

## ğŸš€ How to Run | CÃ¡ch cháº¡y chÆ°Æ¡ng trÃ¬nh

### 1. CÃ i Ä‘áº·t thÆ° viá»‡n:

```bash
pip install opencv-python mediapipe pyautogui pycaw numpy
```

### 2. Cháº¡y chÆ°Æ¡ng trÃ¬nh:

```bash
python main_app.py
```

Ensure your webcam is connected and active.

---

## ğŸ“‚ Project Structure | Cáº¥u trÃºc thÆ° má»¥c

```
Gesture-Control-Framework/
â”‚
â”œâ”€â”€ main.py                     # Main application entry (init UI, threading, routing)
â”œâ”€â”€ modules/                    # Core logic modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hand_tracker.py         # Hand detection & landmark tracking (MediaPipe)
â”‚   â””â”€â”€ controllers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ drawing_controller.py     # Logic for air drawing
â”‚       â”œâ”€â”€ mouse_controller.py       # Gesture to mouse control
â”‚       â”œâ”€â”€ volume_controller.py      # Gesture-based volume logic
â”‚       â””â”€â”€ enhanced_finger_counter_controller.py  # Diagnostic tool (hand label, finger count)
â”œâ”€â”€ requirements.txt            # Dependency list
â”œâ”€â”€ README.md                   # Project overview and usage
â””â”€â”€ .gitignore                  # Ignore cache, venv, etc.
```

---

## ğŸ“ˆ Roadmap | Káº¿ hoáº¡ch phÃ¡t triá»ƒn

* ğŸ–ï¸ Custom gesture sets (swipe, circle...)
* ğŸ® Control 3rd-party apps (PowerPoint, Media Player)
* ğŸ§  Trainable ML gesture classifier
* ğŸ–¥ Cross-platform OS support (Linux/macOS)
* âš™ï¸ Performance benchmark tools

---

## ğŸ“Œ Notes & Credits

AI tools (like ChatGPT) were used for ideation and code generation. Architecture design, logic, integration, and bug fixing were done manually by the author.

Developed by **NgÃ´ Nháº­t NguyÃªn (nnYunaXYZ)** ğŸ‡»ğŸ‡³ â€“ Built for personal learning, GitHub portfolio, and international research preparation (e.g., MIT).

---

## ğŸªª License

Licensed under the **MIT License** â€“ free for personal and academic use.
